{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdgnTlNY2LJa",
        "outputId": "462d6703-7f1d-4772-efa5-f9eb771ae5fc"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQklGarej9Qt",
        "outputId": "58a2db9c-ed43-44dd-f8ea-d6655d23c638"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7ZvkRmLqWyBq"
      },
      "outputs": [],
      "source": [
        "# cr loanwords = ['chanson','auteur','a la mode','académie','après','bourgeois','burlesque','depanneur','detente','ennui','faux pas','fete','fin de siecle','gite','jongleur','lycee','peloton','proletariat','rendezvous','salon']\n",
        "# fr-en loanwords = ['beige','brochure','cafe','camaraderie','cliche','clique','concierge','coup','detour','elite','ensemble','etiquette','facade','fine','foyer','naive','nuance','physique','rapport','reservoir']\n",
        "# literal translations = ['academy','after','author','boredom','cottage','end of century','fashionable','high school','misstep','mockery','pack','party','relaxation','repairman','room','song','minstrel','working class','meeting','middle class']\n",
        "# non-borrowed words = ['fire','nose','water','tongue','blood','bone','rain','name','sweet','fly','night','ear','house','bitter','salt','knee','new','old','thick','long']\n",
        "# en-fr loanwords = ['marketing','business','vintage','spoiler','casting','bestseller','pitch','cool','loser','coach','email','brunch','digital','leader','hacker','manager','jogging','yes','match','shopping']\n",
        "# non-borrowed-words-fr = ['feu','nez','eau','langue','sang','os','pluie','nom','doux','mouche','nuit','oreille','maison','amer','sel','genou','nouveau','ancien','epais','long']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "itOWcU-uXSJ6"
      },
      "outputs": [],
      "source": [
        "alternative_spellings = {'a la mode':'à la mode','académie':'academie','après':'apres','depanneur':'dépanneur','détente':'detente','faux pas':'faux-pas','fete':'fête','fin de siecle':'findesiecle','gite':'gîte','lycee':'lycée','rendezvous':'rendez vous','cafe':'café','cliche':'cliché','elite':'élite','etiquette':'étiquette','facade':'façade','naive':'naïve','end of century':'end-of-century','middle-class':'middle class','bestseller':'best seller','epais':'épais'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yzOjK1gpXUjC"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert-base-multilingual-uncased'\n",
        "words = ['chanson','song']\n",
        "# k_values = [10,25,50,100,150,200]\n",
        "max_k = 50\n",
        "language = 'fr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_5ZGn0PgPz5",
        "outputId": "bd6abc9b-09e3-4655-8a0d-0bc14acef3a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM,CamembertForMaskedLM, CamembertTokenizer\n",
        "import sentencepiece\n",
        "\n",
        "if model_name == \"camembert/camembert-base-ccnet\":\n",
        "  model = CamembertForMaskedLM.from_pretrained(\"camembert/camembert-base-ccnet\",output_hidden_states = True)\n",
        "  tokenizer = CamembertTokenizer.from_pretrained(\"camembert/camembert-base-ccnet\")\n",
        "\n",
        "else:\n",
        "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "  model = BertForMaskedLM.from_pretrained(model_name,output_hidden_states = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y7V3hYNcA4b",
        "outputId": "6834d5b6-b7bb-405f-b17d-5db491514b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=105879, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OkVTn9ige0p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def pre_process_sentence(sentence,target_tokens): # return a tensor with target word masked\n",
        "\n",
        "  # Tokenise input text\n",
        "  tokenized_text = tokenizer.tokenize(sentence)\n",
        "\n",
        "  # Create attention mask\n",
        "  attention_mask = [1] * len(tokenized_text)\n",
        "\n",
        "  target_indices = []\n",
        "  for item in target_tokens:\n",
        "    for i in range(len(tokenized_text)):\n",
        "      if tokenized_text[i:i+len(item)] == item:\n",
        "        tokens_indices = [j for j in range(i,i+len(item)) if i < (512-len(item))]\n",
        "        for k in tokens_indices:\n",
        "          if k not in target_indices:\n",
        "            target_indices.append(k)\n",
        "\n",
        "  for i in target_indices:\n",
        "      tokenized_text[i] = '[MASK]'\n",
        "      attention_mask[i] = 0\n",
        "\n",
        "  input_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(tokenized_text)], dtype=torch.long)\n",
        "  attention_mask_tensor = torch.tensor([attention_mask], dtype=torch.long)\n",
        "  input_tensor = input_tensor.to(device)\n",
        "  attention_mask_tensor = attention_mask_tensor.to(device)\n",
        "\n",
        "  return input_tensor, attention_mask_tensor, target_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-ntMWyegkxL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "def get_predicted_words(input_tensor,attention_mask_tensor,target_indices,model,tokenizer,k):\n",
        "\n",
        "  if input_tensor.size(1) > 512:\n",
        "    # Truncate the input tensor to fit within the model's maximum size\n",
        "    input_tensor = input_tensor[:, :512]\n",
        "    attention_mask_tensor = attention_mask_tensor[:, :512]\n",
        "\n",
        "    # model = model.to(torch.long)\n",
        "\n",
        "    # Feed the input tensor to the model and predict words\n",
        "  with torch.no_grad():\n",
        "      output = model(input_tensor,attention_mask = attention_mask_tensor)\n",
        "\n",
        "  top_k_predictions = {}\n",
        "  for i in target_indices:\n",
        "    masked_token_logits = output.logits[0, i]\n",
        "    masked_token_probs = torch.softmax(masked_token_logits, dim=-1)\n",
        "    top_k_tokens = torch.topk(masked_token_probs, k=k)\n",
        "    predictions = [(tokenizer.decode(token.item())) for token in top_k_tokens.indices]\n",
        "    # top_k_predictions.extend([tokenizer.decode(token.item()) for token in top_k_tokens.indices])\n",
        "    top_k_predictions[i]=[element.replace(' ', '') for element in predictions]\n",
        "\n",
        "\n",
        "  return top_k_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYxfRHV3Xuxd"
      },
      "outputs": [],
      "source": [
        "cr_loanwords = ['chanson','auteur','a la mode','académie','après','bourgeois','burlesque','depanneur','detente','détente','ennui','faux pas','fete','fin de siecle','gite','jongleur','lycee','lycée','peloton','proletariat','rendezvous','salon']\n",
        "fr_en_loanwords = ['beige','brochure','cafe','camaraderie','cliche','clique','concierge','coup','detour','elite','ensemble','etiquette','facade','fine','foyer','naive','nuance','physique','rapport','reservoir']\n",
        "literal_translations = ['academy','after','author','boredom','cottage','end of century','fashionable','high school','misstep','mockery','pack','party','relaxation','repairman','room','song','minstrel','working class','meeting','middle class']\n",
        "non_borrowed_words = ['fire','nose','water','tongue','blood','bone','rain','name','sweet','fly','night','ear','house','bitter','salt','knee','new','old','thick','long']\n",
        "en_fr_loanwords = ['marketing','business','vintage','spoiler','casting','bestseller','pitch','cool','loser','coach','email','brunch','digital','leader','hacker','manager','jogging','yes','match','shopping']\n",
        "non_borrowed_words_fr = ['feu','nez','eau','langue','sang','os','pluie','nom','doux','mouche','nuit','oreille','maison','amer','sel','genou','nouveau','ancien','epais','long']\n",
        "\n",
        "types = {}\n",
        "for w in cr_loanwords:\n",
        "  types[w]= 'cr loanword'\n",
        "\n",
        "for w in fr_en_loanwords:\n",
        "  types[w] = 'fr-en loanword'\n",
        "\n",
        "for w in literal_translations:\n",
        "  types[w] = 'literal translation'\n",
        "\n",
        "for w in non_borrowed_words:\n",
        "  types[w] = 'non borrowed word'\n",
        "\n",
        "for w in en_fr_loanwords:\n",
        "  types[w] = 'en-fr loanword'\n",
        "\n",
        "for w in non_borrowed_words_fr:\n",
        "  types[w] = 'non borrowed word fr'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avmo1f6oRhXV",
        "outputId": "f275ebb5-384b-449a-bf4a-e6dce2ca0fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target word:  oreille\n",
            "Target word:  maison\n",
            "Target word:  amer\n",
            "Target word:  sel\n",
            "Target word:  genou\n",
            "Target word:  nouveau\n",
            "Target word:  ancien\n",
            "Target word:  epais\n",
            "Target word:  long\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "for word in words:\n",
        "\n",
        "  token_instances = 0\n",
        "\n",
        "  if word in alternative_spellings.keys(): # checking if there are alternative spellings and adding these to be masked\n",
        "    target_words = [word,word+'s',alternative_spellings[word],alternative_spellings[word]+'s']\n",
        "  else:\n",
        "    target_words = [word,word+'s']\n",
        "\n",
        "  # Tokenise target word, plurals and alternative spellings\n",
        "  target_tokens = []\n",
        "  for target in target_words:\n",
        "    if tokenizer.tokenize(target.lower()) not in target_tokens: # alternative spellings may be same when tokenised\n",
        "      target_tokens += [tokenizer.tokenize(target.lower())] # producing a list of tuples of tokens, where each tuple is a word\n",
        "\n",
        "  print('Target word: ',word)\n",
        "\n",
        "  with open('Sentence datasets/'+word+'_'+language+'_unique.txt','r') as final_list:\n",
        "    sentences = final_list.readlines()\n",
        "    sentences = [str(sentence.strip()) for sentence in sentences if sentence.strip()]  # Skip empty lines\n",
        "    sentences = sentences[:2000]\n",
        "\n",
        "  word_frequency = {}\n",
        "  runtime_errors = 0\n",
        "  for sentence in sentences:\n",
        "\n",
        "    input_tensor,attention_mask_tensor,target_indices = pre_process_sentence(sentence,target_tokens)\n",
        "\n",
        "    token_instances += len(target_indices) # adding the number of tokens\n",
        "    # print('Sentence number: ',sentences.index(sentence),'Number of masked tokens:',len(target_indices))\n",
        "    if token_instances >= (500*len(target_tokens[0])):\n",
        "      break\n",
        "\n",
        "    if input_tensor!= None:\n",
        "      if len(input_tensor)!= 0:\n",
        "        try:\n",
        "          predictions = get_predicted_words(input_tensor,attention_mask_tensor,target_indices,model,tokenizer,max_k)\n",
        "        except RuntimeError:\n",
        "          runtime_errors += 1\n",
        "        for prediction_list in predictions.values():\n",
        "          for p in prediction_list:\n",
        "            if p in word_frequency.keys():\n",
        "              word_frequency[p]+=1\n",
        "            else:\n",
        "              word_frequency[p]=1\n",
        "\n",
        "\n",
        "  sorted_word_frequency = {k: v for k, v in sorted(word_frequency.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "  with open('Results/MLM_Results/masked_word_guesses_'+model_name+'_'+language+'.csv','a') as GUESSES:\n",
        "    guesseswriter = csv.writer(GUESSES)\n",
        "    guesseswriter.writerow([word, types[word],tokenizer.tokenize(word),sorted_word_frequency])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0Sv0_F1_ocV",
        "outputId": "9e323e5e-589a-4484-83c0-558737c1c905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'long': 367, 'grand': 219, 'tout': 219, 'le': 211, 'petit': 208, 'meme': 208, 'moyen': 204, 'plus': 201, 'temps': 201, 'de': 200, 'bon': 194, 'terme': 190, 'du': 181, 'niveau': 178, 'premier': 176, 'titre': 175, 'monde': 172, 'haut': 167, 'son': 167, 'ce': 167, 'milieu': 162, 'fait': 159, 'cœur': 155, 'un': 153, 'simple': 152, 'nom': 152, 'a': 150, 'second': 140, 'debut': 140, 'seul': 139, 'cours': 137, 'reste': 135, 'dernier': 134, '-': 134, 'gros': 132, 'jour': 130, 'court': 125, 'fort': 123, 'bien': 123, 'en': 122, 'sens': 122, 'nouveau': 121, 'cote': 120, 'bout': 119, 'lieu': 118, 'bord': 118, 'tour': 118, 'fond': 118, 'moins': 116, 'developpement': 115, 'moment': 114, 'la': 112, 'point': 111, 'centre': 111, 'au': 110, 'service': 109, 'double': 107, 'stade': 106, 'sein': 106, 'sans': 105, 'pays': 105, 'large': 101, 'chemin': 99, 'meilleur': 97, 'fil': 97, 'dela': 97, 'site': 96, 'ton': 95, 'tel': 94, ',': 94, 'vieux': 92, 'mauvais': 90, 'depart': 90, 'sommet': 89, 'nombre': 88, 'domaine': 87, 'non': 85, 'et': 85, 'faux': 83, 'sud': 83, 'plein': 82, 'gout': 82, 'leur': 81, 'dessus': 79, 'mal': 78, 'peu': 77, 'cas': 75, 'sujet': 75, 'travail': 74, 'prix': 74, 'profit': 73, '.': 71, 'plan': 71, 'juste': 70, 'beau': 70, 'sur': 68, 'travers': 68, 'libre': 67, 'des': 66, 'mieux': 66, 'tres': 65, 'fin': 65, 'bas': 64, '...': 64, 'mon': 63, 'rythme': 63, 'deuxieme': 62, 'jeune': 61, 'vrai': 60, 'que': 60, 'sol': 60, 'nord': 60, 'chaque': 60, 'futur': 59, 'faire': 58, 'dehors': 58, 'autre': 57, 'par': 55, 'quelque': 55, 'voyage': 55, 'champ': 55, 'final': 55, ':': 54, 'est': 54, 'sortir': 54, 'retour': 54, 'important': 53, 'les': 53, 'passage': 53, 'pas': 51, 'pied': 50, 'livre': 49, 'ou': 49, 'soir': 49, 'regard': 49, 'faible': 48, 'longue': 48, 'droit': 48, 'parcours': 48, 'contraire': 47, 'troisieme': 46, 'pour': 46, 'courant': 46, 'propre': 45, 'encore': 45, 'complet': 45, 'choix': 44, 'difficile': 43, 'certain': 43, 'vaste': 43, 'grande': 43, 'tot': 43, 'celebre': 42, 'mot': 42, 'maximum': 41, 'jardin': 41, 'passe': 40, 'franc': 39, 'deux': 39, 'terrain': 39, 'marche': 37, 'trace': 37, 'pont': 37, 'lac': 37, 'matin': 37, 'une': 36, 'l': 36, '##s': 35, 'reseau': 35, 'moindre': 34, 'devant': 34, 'rapide': 33, 'veritable': 33, 'comme': 33, 'loin': 33, 'bonheur': 33, 'petits': 32, 'probleme': 32, 'projet': 32, 'termine': 32, 'cette': 32, 'ancien': 31, '2': 31, 'village': 31, 'facile': 30, 'dit': 30, 'compte': 30, 'mais': 30, 'mois': 30, 'musee': 30, '1': 30, 'grands': 28, '##e': 28, 'quartier': 28, 'code': 28, 'jeu': 28, 'type': 27, 'longs': 27, 'nombreux': 27, 'excellent': 27, 'lent': 26, 'nouvel': 26, 'precedent': 26, 'coup': 26, 'courte': 26, 'corps': 26, 'bons': 26, 'c': 26, 'dessous': 26, 'poids': 25, '!': 25, 'territoire': 25, 'theme': 25, 'quel': 25, 'canal': 25, 'avec': 24, 'aussi': 24, 'ces': 24, 'secret': 24, 'se': 24, 'programme': 24, 'concept': 24, 'the': 24, 'train': 24, 'concours': 24, 'leger': 23, '«': 23, 'metre': 23, 'trois': 23, 'souvent': 23, 'savoir': 23, 'parc': 23, 'cet': 23, 'rare': 22, 'riche': 22, '/': 22, 'divers': 22, 'notre': 22, 'chateau': 22, 'contact': 22, 'theatre': 22, 'ciel': 22, 'souvenir': 22, 'term': 22, 'puissant': 21, 'breve': 21, 'qui': 21, 'si': 21, 'unique': 21, 'club': 21, 'total': 21, 'lendemain': 21, 'bois': 21, 'port': 21, 'present': 20, 'short': 20, 'nouveaux': 20, 'siecle': 20, 'public': 20, 'bateau': 20, 'film': 20, 'interessant': 19, 'utile': 19, 'possible': 19, 'proche': 19, ';': 19, 'quelques': 19, '[UNK]': 19, 'differents': 19, 'lancement': 19, '1ᵉʳ': 19, 'modele': 19, 'plat': 19, 'faite': 19, \"'\": 19, 'd': 19, 'groupe': 19, 'cher': 18, 'dur': 18, 'quatrieme': 18, 'alors': 18, '4': 18, '3': 18, 'soleil': 18, 'longtemps': 18, 'carrefour': 18, 'an': 18, 'voir': 18, 'toit': 18, 'mur': 18, 'plateau': 18, 'base': 17, 'beaucoup': 17, 'donc': 17, 'quatre': 17, 'beaux': 17, 'premiers': 17, 'immense': 17, 'departement': 17, 'lang': 17, 'triple': 17, 'but': 17, 'desert': 17, 'modeste': 16, 'precis': 16, 'toujours': 16, 'meilleurs': 16, 'succes': 16, 'vite': 16, 'pres': 16, 'francais': 16, 'silence': 16, 'sort': 16, 'on': 16, 'bel': 16, 'paysage': 16, 'eu': 16, 'bassin': 16, 'couple': 16, 'cinquieme': 15, 'apres': 15, 'ainsi': 15, 'jeunes': 15, 'grandes': 15, '?': 15, 'medium': 15, 'autres': 15, 'corto': 15, 'systeme': 15, 'vide': 15, 'tunnel': 15, 'transport': 15, 'fleuve': 15, 'dans': 15, 'suivi': 15, 'roi': 14, 'ses': 14, 'hauts': 14, 'plusieurs': 14, '5': 14, 'bras': 14, 'nos': 14, 'tous': 14, 'visage': 14, 'reel': 14, 'sa': 14, 'propos': 14, '10': 14, 'in': 14, 'journal': 14, 'rapport': 14, 'courts': 14, 'populaire': 13, 'eleve': 13, 'complexe': 13, 'impossible': 13, 'terrible': 13, '##ur': 13, '(': 13, 'seulement': 13, 'dos': 13, 'simples': 13, 'anciens': 13, 'rang': 13, 'rapidement': 13, 'circuit': 13, 'rares': 13, 'style': 13, 'termes': 13, 'col': 13, 'diametre': 13, 'coin': 13, 'materiel': 12, 'sous': 12, 'recit': 12, 'ami': 12, 'cinq': 12, 'memes': 12, 'mystere': 12, 'chien': 12, 'triste': 12, 'respect': 12, 'il': 12, 'quelle': 12, 'remarquable': 12, 'same': 12, 'midi': 12, 'minimum': 12, 'secteur': 12, 'hors': 11, '##u': 11, 'grave': 11, 'surtout': 11, 'dix': 11, 'tard': 11, 'front': 11, 'rond': 11, 'commerce': 11, 'siege': 11, 'derniers': 11, 'multiples': 11, 'pur': 11, 'longueur': 11, '##a': 11, 'papier': 11, 'fils': 11, 'classement': 11, 'sable': 11, 'littoral': 11, 'seuil': 11, 'vol': 11, 'b': 11, 'y': 11, 'ete': 11, 'principal': 10, '3ᵉ': 10, 'basse': 10, 'leurs': 10, 'huit': 10, 'longues': 10, '6': 10, '7': 10, 'certains': 10, 'froid': 10, 'royaume': 10, 'restant': 10, 'gre': 10, 'boulevard': 10, '\"': 10, 'nous': 10, 'printemps': 10, 'end': 10, 'salon': 10, 'produit': 10, 'special': 10, 'climat': 10, 'mi': 10, 'vu': 10, 'camp': 10, 'profil': 10, 'efficace': 9, 'necessaire': 9, 'risque': 9, 'langage': 9, 'porte': 9, 'sejour': 9, 'peuple': 9, 'six': 9, '##i': 9, 'enorme': 9, 'retrait': 9, 'trafic': 9, 'transfert': 9, 'distance': 9, 'standard': 9, 'partage': 9, '2ᵉ': 9, 'aucun': 9, 'connu': 9, 'moi': 9, '20': 9, 'aux': 9, 'belle': 9, 'mesure': 9, 'chantier': 9, ')': 9, 'festival': 9, 'domicile': 9, 'depot': 9, 'palais': 9, 'terre': 9, 'moulin': 9, 'voyages': 9, 'relief': 9, 'haute': 9, 'sixieme': 8, 'notamment': 8, 'riches': 8, 'quart': 8, 'tiers': 8, 'politique': 8, 'controle': 8, 'importante': 8, 'moyenne': 8, 'vie': 8, 'principaux': 8, 's': 8, 'cheval': 8, 'different': 8, 'personnel': 8, 'dimanche': 8, 'page': 8, 'secours': 8, 'my': 8, 'cent': 8, 'i': 8, 'e': 8, 'tels': 8, 'celebres': 8, 'pavillon': 8, 'surface': 8, 'hauteur': 8, 'taille': 8, 'homme': 8, 'chef': 8, 'va': 8, 'begin': 8, 'longo': 8, 'phare': 8, 'inconnu': 8, 'solide': 8, 'utilise': 7, 'val': 7, 'navire': 7, 'etait': 7, 'comment': 7, 'rien': 7, 'parfois': 7, 'cela': 7, 'mille': 7, 'tournage': 7, 'mouvement': 7, 'facilement': 7, 'petite': 7, 'parking': 7, 'avoir': 7, 'principe': 7, 'label': 7, 'no': 7, 'anglais': 7, 'of': 7, 'age': 7, 'reference': 7, 'sept': 7, 'paris': 7, 'and': 7, 'cycle': 7, 'chant': 7, 'rapides': 7, 'rocher': 7, 'cafe': 7, 'largeur': 7, 'profondeur': 7, 'feu': 7, 'ne': 7, '##t': 7, '##r': 7, 'resultat': 7, 'clair': 7, 'amour': 7, 'new': 7, 'car': 7, 'usage': 7, 'lit': 7, 'contour': 7, 'quai': 7, 'mer': 7, 'sont': 7, 'recherche': 6, 'cruel': 6, 'egalement': 6, 'dire': 6, 'donne': 6, 'eleves': 6, 'graves': 6, 'seuls': 6, 'combat': 6, 'drame': 6, 'phenomene': 6, 'enfants': 6, 'etre': 6, 'presque': 6, 'partir': 6, 'metier': 6, 'etant': 6, 'vent': 6, 'el': 6, 'nombreuses': 6, 'ma': 6, 'france': 6, 'o': 6, 'traitement': 6, 'septieme': 6, 'paradis': 6, 'delta': 6, 'complexes': 6, 'je': 6, 'sport': 6, '##d': 6, 'rouge': 6, 'lien': 6, 'college': 6, 'puis': 6, 'cinema': 6, 'soit': 6, 'tu': 6, '##y': 6, '##o': 6, 'enfant': 6, 'taxi': 6, 'avant': 6, 'ferme': 6, 'cadre': 6, 'support': 6, 'volume': 6, 'fine': 6, 'instant': 6, 'pratique': 5, 'probable': 5, 'besoin': 5, 'naturel': 5, '##x': 5, '##z': 5, 'blanc': 5, '##urs': 5, 'destin': 5, 'fut': 5, 'particulierement': 5, 'precise': 5, 'recensement': 5, 'tant': 5, 'vitesse': 5, 'heros': 5, 'japon': 5, 'brief': 5, 'good': 5, 'face': 5, 'parler': 5, 'travailler': 5, '12': 5, '9': 5, 'su': 5, 'pere': 5, 'di': 5, 'moyens': 5, 'lion': 5, 'importants': 5, 'barrage': 5, 'panorama': 5, 'mots': 5, 'progres': 5, 'essai': 5, 'avion': 5, 'contrat': 5, 'air': 5, 'concert': 5, 'peut': 5, 'partout': 5, '##n': 5, 'noir': 5, 'fruit': 5, 'parallele': 5, 'continent': 5, 'disque': 5, 'genre': 5, 'tourisme': 5, 'detroit': 5, 'great': 5, 'maitre': 5, 'place': 5, 'mode': 5, 'ruisseau': 5, 'reve': 5, 'route': 5, 'documentaire': 5, 'peine': 5, 'tort': 5, 'big': 5, 'high': 5, 'bonnes': 5, 'carre': 5, 'portee': 5, 'micro': 5, 'nez': 5, 'foyer': 5, 'cout': 5, 'appele': 5, 'medio': 5, 'tube': 5, 'rayon': 5, 'texte': 5, 'art': 5, '4ᵉ': 5, '5ᵉ': 5, 'm': 5, 'hameau': 5, 'morceau': 5, 'maintenant': 5, 'batiment': 5, 'technique': 4, 'economique': 4, 'commercial': 4, 'financier': 4, 'frais': 4, 'latin': 4, 'mariage': 4, 'directement': 4, 'faites': 4, 'particulier': 4, 'questions': 4, 'utiles': 4, 'regne': 4, 'constant': 4, 'violent': 4, 'severe': 4, 'fragile': 4, 'processus': 4, 'contexte': 4, 'generalement': 4, 'camping': 4, 'saut': 4, 'nouvelles': 4, 'femmes': 4, 'discours': 4, 'petites': 4, 'histoire': 4, 'solo': 4, 'deja': 4, 'document': 4, 'test': 4, 'international': 4, 'match': 4, '8': 4, 'to': 4, 'effet': 4, 'brave': 4, 'noble': 4, 'massif': 4, 'beton': 4, 'cimetiere': 4, 'ministere': 4, 'vers': 4, 'seconde': 4, 'moteur': 4, 'ca': 4, 'limite': 4, '##le': 4, 'part': 4, '##de': 4, '##re': 4, '##l': 4, 'forum': 4, 'riviere': 4, 'accessible': 4, 'golfe': 4, 'tresor': 4, 'tournoi': 4, 'joueur': 4, 'bourg': 4, 'tourne': 4, 'video': 4, 'jours': 4, 'vols': 4, 'oiseau': 4, 'garcon': 4, 'ultime': 4, 'relais': 4, 'ouvert': 4, 'dvd': 4, 'montage': 4, 'little': 4, 'magazine': 4, 'fonctionnement': 4, 'north': 4, 'green': 4, 'debit': 4, 'suite': 4, 'reduit': 4, '##ment': 4, 'land': 4, 'doubles': 4, 'recherches': 4, 'propres': 4, 'logement': 4, 'celui': 4, 'images': 4, 'contenu': 4, 'emplacement': 4, 'format': 4, 'recent': 4, 'cherche': 4, 'pointe': 4, 'gratuit': 4, '##er': 4, 'scientifique': 3, 'avance': 3, 'arme': 3, 'pousse': 3, 'adapte': 3, 'frequent': 3, 'hard': 3, 'interdit': 3, 'rude': 3, 'bizarre': 3, '##ux': 3, 'del': 3, 'uniquement': 3, 'chacun': 3, 'plutot': 3, 'toutes': 3, 'choisi': 3, 'ceci': 3, 'prevu': 3, 'pourquoi': 3, 'pieds': 3, 'braves': 3, 'dieux': 3, 'brutal': 3, 'considerable': 3, 'intense': 3, 'durable': 3, 'sensible': 3, 'critique': 3, 'trouble': 3, 'traite': 3, 'noirs': 3, 'paroles': 3, 'livres': 3, 'tenir': 3, 'œil': 3, 'canada': 3, 'trop': 3, 'vraiment': 3, 'assez': 3, 'bonne': 3, 'statut': 3, 'business': 3, 'marketing': 3, 'or': 3, 'exact': 3, 'date': 3, 'record': 3, 'chapitre': 3, 'devenir': 3, 'neuf': 3, '15': 3, '30': 3, 'quinze': 3, '14': 3, '13': 3, 'contre': 3, 'chinois': 3, 'pierre': 3, 'sou': 3, 'ils': 3, 'vingt': 3, '100': 3, 'nouvelle': 3, 'dure': 3, 'bal': 3, 'jamais': 3, 'canyon': 3, 'puits': 3, 'guide': 3, 'peintre': 3, 'dessin': 3, 'lumiere': 3, 'toile': 3, 'fer': 3, 'exemple': 3, 'accident': 3, 'bebe': 3, 'ballon': 3, 'ii': 3, 'da': 3, 'musique': 3, 'dont': 3, 'net': 3, 'entre': 3, '##c': 3, '##ver': 3, 'blog': 3, 'web': 3, 'llarg': 3, 'interessante': 3, 'golf': 3, 'pacifique': 3, 'love': 3, 'this': 3, 'live': 3, 'g': 3, 'championnat': 3, 'temple': 3, 'havre': 3, 'mari': 3, 'seigneur': 3, 'lycee': 3, 'ecrit': 3, 'jouer': 3, 'presente': 3, 'catalogue': 3, 'hotel': 3, 'vivant': 3, 'spectacle': 3, 'rand': 3, 'resume': 3, 'episode': 3, 'extrait': 3, 'signal': 3, 'monte': 3, 'loi': 3, 'vous': 3, 'full': 3, 'lot': 3, 'forts': 3, 'pratiques': 3, 'officiel': 3, 'south': 3, 'west': 3, 'silver': 3, 'sand': 3, 'washington': 3, 'indian': 3, 'danger': 3, 'detail': 3, 'fini': 3, 'calcul': 3, 'tableau': 3, 'role': 3, 'constante': 3, 'duree': 3, 'note': 3, 'relatif': 3, 'echanges': 3, 'jeux': 3, 'futures': 3, 'projets': 3, 'vivre': 3, 'relations': 3, 'rencontres': 3, 'field': 3, 'z': 3, 'do': 3, 'v': 3, 'echec': 3, 'annees': 3, 'trouve': 3, 'star': 3, 'manoir': 3, 'quand': 3, 'politiques': 3, 'ressources': 3, 'memoires': 3, 'choses': 3, 'films': 3, 'dose': 3, 'suicide': 3, 'mort': 3, 'cercle': 3, 'compact': 3, 'voisin': 3, 'elegant': 3, 'ayant': 3, 'lui': 3, 'ci': 3, 'nes': 3, 'cert': 3, 'hautes': 3, 'grain': 3, 'super': 3, 'white': 3, 'xxᵉ': 3, '8ᵉ': 3, 'demi': 3, 'metres': 3, 'course': 3, 'grosse': 3, 'blonde': 3, 'termin': 3, 'piano': 3, 'contenant': 3, 'truc': 3, 'fragment': 3, 'photo': 3, 'reussi': 2, 'facil': 2, 'decide': 2, 'logique': 2, 'necessite': 2, '##ue': 2, '##uil': 2, '##ure': 2, 'saint': 2, 'roman': 2, 'capitaine': 2, 'principalement': 2, 'demande': 2, 'simplement': 2, 'yeux': 2, '##eux': 2, '##is': 2, '##aux': 2, 'liban': 2, 'conseil': 2, 'legal': 2, 'continue': 2, 'stable': 2, 'massacre': 2, 'desastre': 2, 'gouvernement': 2, 'raison': 2, 'difficulte': 2, 'faut': 2, 'autant': 2, 'tramway': 2, 'bus': 2, 'siecles': 2, 'tours': 2, 'ans': 2, 'armes': 2, 'sujets': 2, 'largo': 2, 'sang': 2, 'axe': 2, 'arriere': 2, 'crane': 2, 'muscle': 2, 'vietnam': 2, 'management': 2, 'office': 2, '##ie': 2, 'emploi': 2, 'depuis': 2, 'vient': 2, 'lors': 2, 'indien': 2, 'nomme': 2, '25': 2, '16': 2, '17': 2, '24': 2, 'charles': 2, 'so': 2, 'dei': 2, 'ra': 2, 'fra': 2, 'me': 2, 'con': 2, 'environnement': 2, 'enfin': 2, '50': 2, 'sacre': 2, 'frequemment': 2, 'connus': 2, 'peuples': 2, 'presents': 2, 'volcan': 2, 'monument': 2, 'zoo': 2, 'couleur': 2, 'verre': 2, 'lecture': 2, 'ligne': 2, 'taux': 2, 'camion': 2, 'million': 2, 'pa': 2, 'a1': 2, 'ti': 2, 'na': 2, 'ap': 2, '##f': 2, '##m': 2, '=': 2, '##te': 2, 'ici': 2, '##se': 2, 'baton': 2, 'main': 2, 'dis': 2, 'perdu': 2, 'vos': 2, 'rec': 2, 'ex': 2, 'ob': 2, 'sub': 2, '##vre': 2, 'bleu': 2, '##ve': 2, '##fe': 2, '##ge': 2, 'quotidien': 2, 'palmares': 2, 'portail': 2, 'comencament': 2, 'endroit': 2, 'disponible': 2, 'happy': 2, 'first': 2, '*': 2, 'original': 2, 'comte': 2, 'vallee': 2, 'mont': 2, 'ville': 2, 'medecin': 2, 'ecole': 2, 'espace': 2, 'parisien': 2, 'informatique': 2, 'superieur': 2, 'prive': 2, 'lire': 2, 'mise': 2, 'sera': 2, 'actuel': 2, 'suivant': 2, 'afin': 2, 'es': 2, 'rose': 2, 'album': 2, 'rock': 2, '3d': 2, 'joue': 2, '##que': 2, 'vive': 2, '##hain': 2, '##in': 2, '##um': 2, 'trains': 2, 'safari': 2, 'garage': 2, 'weekend': 2, 'divorce': 2, 'reglement': 2, 'article': 2, 'message': 2, 'interview': 2, 'introduction': 2, 'entretien': 2, 'invite': 2, 'accueil': 2, 'sketch': 2, 'police': 2, 'rend': 2, 'luc': 2, 'small': 2, 'whole': 2, 'some': 2, 'limited': 2, 'more': 2, 'many': 2, 'proches': 2, 'importantes': 2, 'limites': 2, '##on': 2, 'surprise': 2, 'exercice': 2, 'regime': 2, 'palm': 2, 'newport': 2, 'huntington': 2, 'miami': 2, 'laguna': 2, 'venice': 2, 'daytona': 2, 'monterey': 2, 'sunset': 2, 'coral': 2, 'virginia': 2, 'beverly': 2, 'marin': 2, 'omaha': 2, 'pacific': 2, 'sunny': 2, 'beach': 2, 'sandy': 2, 'middle': 2, 'santa': 2, 'berkeley': 2, 'golden': 2, 'hollywood': 2, 'clear': 2, 'california': 2, 'orange': 2, 'salt': 2, 'salut': 2, 'inferieur': 2, 'sec': 2, '+': 2, 'banc': 2, 'superficie': 2, 'eau': 2, 'distant': 2, 'dragon': 2, 'champion': 2, 'pole': 2, 'portrait': 2, 'sexe': 2, 'prendre': 2, 'conferences': 2, 'parole': 2, 'connaitre': 2, 't': 2, 'h': 2, 'p': 2, 'r': 2, 'examen': 2, 'entrainement': 2, 'master': 2, 'laboratoire': 2, '##h': 2, 'dune': 2, '##k': 2, 'day': 2, 'uns': 2, 'arret': 2, 'interval': 2, 'budget': 2, 'mis': 2, 'pris': 2, 'science': 2, 'blue': 2, 'restaurant': 2, 'virus': 2, 'belles': 2, 'enormes': 2, 'mes': 2, 'jaune': 2, 'quoi': 2, 'parce': 2, 'problemes': 2, 'documents': 2, 'reseaux': 2, 'frontieres': 2, 'rapports': 2, 'situations': 2, 'textes': 2, 'secrets': 2, 'dialogues': 2, 'lettres': 2, 'travaux': 2, 'donnees': 2, 'faits': 2, 'guerre': 2, 'critiques': 2, 'journaux': 2, 'passages': 2, 'notes': 2, 'femme': 2, 'arbre': 2, 'ouvrage': 2, 'terminus': 2, 'poeme': 2, 'changement': 2, 'wikipedia': 2, 'faisant': 2, '1er': 2, 'te': 2, 'rouges': 2, 'blancs': 2, 'electriques': 2, 'rhone': 2, 'flux': 2, 'doit': 2, 'minute': 2, 'incident': 2, 'heure': 2, 'duel': 2, 'angle': 2, 'pain': 2, 'procede': 2, 'termino': 2, '##it': 2, 'black': 2, 'model': 2, 'old': 2, 'top': 2, 'al': 2, 'possibles': 2, 'cependant': 2, 'abc': 2, 'los': 2, 'etats': 2, 'xixᵉ': 2, 'premiere': 2, 'humain': 2, 'dense': 2, 'developpe': 2, 'debat': 2, 'mai': 2, '7ᵉ': 2, 'pic': 2, 'aller': 2, 'per': 2, 'mozart': 2, 'musicien': 2, 'chanteur': 2, 'dieu': 2, 'artiste': 2, 'poete': 2, 'differentes': 2, 'etrangers': 2, 'grace': 2, 'allant': 2, 'passant': 2, 'varie': 2, 'national': 2, 'jet': 2, 'design': 2, '##ut': 2, 'maniere': 2, 'indiens': 2, 'raid': 2, 'terms': 2, 'termen': 2, 'poche': 2, 'carriere': 2, 'francs': 2, 'publics': 2, 'arrive': 2, 'venu': 2, 'arrete': 2, 'complement': 2, 'placement': 2, 'mineur': 2, 'cap': 2, 'autour': 2, 'copper': 2, 'hiver': 2, 'sexy': 2, 'made': 2, 'japonais': 2, 'pilote': 2, 'luxe': 2, 'versant': 2, 'zero': 2, 'evenement': 2, 'football': 2, 'dimension': 2, 'metro': 2, 'forme': 2, 'masse': 2, 'calibre': 2, 'manque': 2, 'future': 2, '##ᵉ': 2, 'qu': 2, 'moderne': 1, 'illegal': 1, 'dificil': 1, 'oblige': 1, 'capable': 1, 'sanskrit': 1, '##q': 1, 'roma': 1, 'professeur': 1, 'davantage': 1, 'attention': 1, 'particuliere': 1, 'essentiellement': 1, 'ideal': 1, 'traits': 1, '##es': 1, '##iques': 1, '##ies': 1, '##iges': 1, '##iers': 1, '##euses': 1, '##iens': 1, '##ibles': 1, '##ets': 1, '##ens': 1, 'consequent': 1, 'genocide': 1, 'conflit': 1, 'meurtre': 1, 'crash': 1, 'chose': 1, 'precisement': 1, 'normale': 1, 'internationale': 1, 'legere': 1, 'premieres': 1, 'poetes': 1, 'evenements': 1, 'editions': 1, 'mers': 1, 'annales': 1, 'poemes': 1, 'lieux': 1, 'romains': 1, 'seconds': 1, 'epee': 1, 'arm': 1, 'novembre': 1, 'anschluss': 1, 'compter': 1, 'congres': 1, 'week': 1, 'registre': 1, 'caractere': 1, 'lobby': 1, 'action': 1, 'association': 1, 'question': 1, '##ing': 1, 'professionnel': 1, 'independant': 1, 'anniversaire': 1, 'issue': 1, 'annee': 1, 'douze': 1, 'jean': 1, 'chine': 1, 'georges': 1, 'maurice': 1, 'monsieur': 1, 'alexandre': 1, 'michel': 1, 'laos': 1, 'alain': 1, 'tibet': 1, 'ha': 1, 'oh': 1, 'nam': 1, 'tho': 1, 'ho': 1, 'lord': 1, 'seu': 1, 'he': 1, 'anne': 1, 've': 1, 'suo': 1, 'soan': 1, 'toe': 1, 'god': 1, 'as': 1, 'san': 1, 'biologie': 1, 'bio': 1, 'index': 1, 'evolution': 1, 'ph': 1, 'eco': 1, 'impact': 1, 'classification': 1, 'interet': 1, 'valeur': 1, 'relation': 1, 'patrimoine': 1, 'situation': 1, '18': 1, '21': 1, '200': 1, '40': 1, '28': 1, '26': 1, 'fier': 1, 'forte': 1, 'fertile': 1, 'maroc': 1, 'largement': 1, 'populaires': 1, 'rio': 1, 'prado': 1, 'cerro': 1, 'belvedere': 1, 'chili': 1, 'parque': 1, 'dolmen': 1, 'verde': 1, 'jardim': 1, 'refuge': 1, 'patio': 1, 'couleurs': 1, 'qualite': 1, 'gamme': 1, 'temperature': 1, 'nuit': 1, 'fibre': 1, 'puissance': 1, 'frequence': 1, 'precision': 1, 'chaine': 1, 'carbone': 1, 'tension': 1, 'cristal': 1, 'securite': 1, 'appel': 1, 'echange': 1, 'eni': 1, 'sncf': 1, 'peugeot': 1, 'fiat': 1, 'renault': 1, 'a4': 1, 'mixte': 1, 'agricole': 1, 'europeen': 1, 'audi': 1, 'fx': 1, 'mini': 1, 'alfa': 1, 'iso': 1, 'vc': 1, 'fia': 1, 'fn': 1, 'gt': 1, 'citroen': 1, 'ia': 1, 'ib': 1, 'alpine': 1, 'pi': 1, 'fa': 1, 'vo': 1, 'ta': 1, 'toute': 1, '[': 1, 'lou': 1, 'offer': 1, 'beni': 1, 'consta': 1, 'plain': 1, 'fit': 1, 'vit': 1, 'sien': 1, 'mien': 1, 'demon': 1, 'hon': 1, 'ingen': 1, 'aven': 1, 'met': 1, 'amin': 1, 'grandi': 1, 'pret': 1, 'sorti': 1, 'permet': 1, 'pen': 1, '##au': 1, '##bre': 1, '##tte': 1, '##uille': 1, '##vres': 1, '##vin': 1, '##let': 1, '##mont': 1, '##dre': 1, '##vert': 1, '##vet': 1, '##vra': 1, 'brun': 1, '##vr': 1, '##bert': 1, '##don': 1, '##veu': 1, 'website': 1, 'sites': 1, 'facebook': 1, 'bureau': 1, 'myspace': 1, 'commence': 1, 'debuts': 1, 'start': 1, 'differente': 1, 'nome': 1, 'name': 1, 'mines': 1, 'region': 1, 'ports': 1, 'compagnie': 1, 'sucre': 1, 'petrol': 1, 'mexique': 1, 'gaz': 1, 'world': 1, 'beautiful': 1, 'hello': 1, 'here': 1, 'dance': 1, 'welcome': 1, 'vintage': 1, 'carnaval': 1, 'dia': 1, 'dame': 1, 'chevalier': 1, 'maire': 1, '##jon': 1, '##lle': 1, 'lyon': 1, 'cite': 1, 'pascal': 1, 'blaise': 1, 'roger': 1, 'brevet': 1, 'albert': 1, 'sante': 1, 'louis': 1, 'caen': 1, 'radio': 1, 'garnier': 1, 'lille': 1, 'ecrite': 1, 'utilisee': 1, 'aa': 1, 'belge': 1, 'x': 1, 'tournee': 1, 'cassette': 1, 'cd': 1, 'numerique': 1, 'suisse': 1, 'musical': 1, '2000': 1, 'chanson': 1, 'stereo': 1, 'veut': 1, '##ffle': 1, 'parle': 1, 'meurt': 1, 'chante': 1, 'vacances': 1, 'danube': 1, 'ranch': 1, 'adolescent': 1, 'frere': 1, 'avenir': 1, 'chemins': 1, 'sel': 1, 'comite': 1, 'essentiel': 1, 'industriel': 1, 'ende': 1, 'at': 1, 'chez': 1, 'ad': 1, 'synopsis': 1, 'cameo': 1, 'detaille': 1, 'tele': 1, 'cartoon': 1, 'bulletin': 1, 'scenario': 1, 'proximite': 1, 'definition': 1, 'internet': 1, 'force': 1, 'few': 1, 'difficult': 1, 'very': 1, 'fair': 1, 'half': 1, 'last': 1, 'busy': 1, 'wonderful': 1, 'thousand': 1, 'real': 1, 'particular': 1, 'rough': 1, 'nice': 1, 'given': 1, 'longer': 1, 'young': 1, 'bad': 1, 'much': 1, 'strange': 1, 'lovely': 1, 'single': 1, 'poor': 1, 'time': 1, 'odd': 1, 'slow': 1, 'ages': 1, 'troubles': 1, 'varies': 1, 'favorables': 1, '##able': 1, '##ables': 1, '##age': 1, '##ant': 1, '##ole': 1, '##ons': 1, '##out': 1, 'equipe': 1, '##lage': 1, '##oir': 1, '##aire': 1, '##ir': 1, 'ensemble': 1, 'memorial': 1, 'palo': 1, 'sea': 1, 'spanish': 1, 'carmel': 1, 'ocean': 1, 'costa': 1, 'trinity': 1, 'jacksonville': 1, 'pearl': 1, 'brighton': 1, 'charleston': 1, 'deer': 1, 'clark': 1, 'auburn': 1, 'wake': 1, 'chicago': 1, 'oakland': 1, 'californie': 1, 'sunshine': 1, 'lente': 1, 'egal': 1, 'variable': 1, 'min': 1, '##inaire': 1, '##dite': 1, '##ite': 1, 'licence': 1, 'citation': 1, 'financiere': 1, 'satisfaction': 1, 'conditions': 1, '##fait': 1, '##ire': 1, '##nite': 1, '##cite': 1, '##matique': 1, 'nil': 1, 'telles': 1, 'fosse': 1, 'bastion': 1, 'maritime': 1, 'flotte': 1, 'profonde': 1, 'environ': 1, 'enceinte': 1, 'distante': 1, 'vainqueur': 1, 'rallye': 1, 'legs': 1, 'trait': 1, 'lait': 1, 'laisser': 1, 'perdre': 1, 'participer': 1, 'voix': 1, 'dialogue': 1, 'vies': 1, 'communication': 1, 'f': 1, 'af': 1, 'w': 1, 'j': 1, 'studio': 1, 'dun': 1, 'tree': 1, 'fir': 1, '##ling': 1, 'habitat': 1, '##bain': 1, 'plats': 1, 'attendre': 1, 'heures': 1, 'tempo': 1, 'metrage': 1, 'pose': 1, 'servi': 1, 'rhode': 1, 'cambridge': 1, 'vancouver': 1, 'garden': 1, 'monkey': 1, 'hong': 1, 'mother': 1, 'oxford': 1, 'down': 1, 'british': 1, 'miss': 1, 'cross': 1, 'one': 1, 'greenwich': 1, 'lonely': 1, 'home': 1, 'london': 1, 'scotland': 1, 'broken': 1, 'medicine': 1, 'silicon': 1, 'queens': 1, 'boston': 1, 'marchand': 1, 'marais': 1, 'vin': 1, 'syndrome': 1, 'gross': 1, 'median': 1, 'sida': 1, 'courage': 1, 'liens': 1, 'messages': 1, 'droits': 1, 'archives': 1, 'interviews': 1, 'medias': 1, 'photos': 1, 'informations': 1, 'ouvrages': 1, 'sources': 1, 'analyses': 1, 'etudes': 1, 'essais': 1, 'programmes': 1, 'histoires': 1, 'techniques': 1, 'references': 1, 'discussions': 1, 'conversations': 1, 'pages': 1, 'publications': 1, 'articles': 1, 'este': 1, 'cannabis': 1, 'rate': 1, 'cancer': 1, 'diagnostic': 1, 'segment': 1, 'cortex': 1, 'metal': 1, 'mecanisme': 1, 'objet': 1, 'arc': 1, 'construit': 1, 'occupe': 1, 'etage': 1, 'bati': 1, 'visible': 1, 'compose': 1, 'complete': 1, 'merite': 1, 'biais': 1, 'remplacement': 1, 'google': 1, 'wiki': 1, 'langue': 1, 'menu': 1, 'logiciel': 1, 'voc': 1, '2e': 1, 'etranger': 1, 'humains': 1, 'marins': 1, 'males': 1, 'elles': 1, 'li': 1, '##ce': 1, '##da': 1, '##mone': 1, '##he': 1, 'respecte': 1, 'culture': 1, 'rive': 1, 'pires': 1, 'nobles': 1, 'plans': 1, 'points': 1, 'postes': 1, 'tons': 1, 'fonds': 1, 'formats': 1, 'terrains': 1, 'circuits': 1, 'angles': 1, 'milieux': 1, 'laps': 1, 'moments': 1, 'pin': 1, 'bot': 1, 'phrase': 1, '##ait': 1, 'ː': 1, 'hybrid': 1, 'twin': 1, 'diesel': 1, 'electric': 1, 'luxury': 1, 'body': 1, 'heavy': 1, 'baby': 1, 'dual': 1, 'american': 1, 'speed': 1, 'smart': 1, 'truck': 1, 'family': 1, 'classic': 1, 'sains': 1, 'eux': 1, 'melbourne': 1, 'pie': 1, 'valeurs': 1, 'lourdes': 1, 'places': 1, 'espaces': 1, 'xviiiᵉ': 1, 'xvᵉ': 1, 'xviiᵉ': 1, 'xviᵉ': 1, 'xivᵉ': 1, 'xiiiᵉ': 1, 'xiiᵉ': 1, 'segle': 1, 'xv': 1, 'xiᵉ': 1, '~': 1, 'bande': 1, 'cine': 1, 'derniere': 1, 'kilometres': 1, 'rue': 1, 'gran': 1, 'diffuse': 1, 'mobile': 1, '##ny': 1, 'litteraire': 1, 'historique': 1, 'reconnu': 1, 'commun': 1, 'parti': 1, 'danse': 1, 'ni': 1, 'на': 1, 'alle': 1, 'в': 1, 'у': 1, 'في': 1, 'στα': 1, 'nelle': 1, 'در': 1, 'delle': 1, 'nei': 1, 'з': 1, 'ai': 1, '6ᵉ': 1, 'prime': 1, 'patient': 1, '2d': 1, 'forca': 1, 'serra': 1, 'proven': 1, 'λ': 1, 'mera': 1, 'valle': 1, 'una': 1, 'quarante': 1, 'dramatique': 1, 'fatal': 1, 'vain': 1, 'beethoven': 1, 'ur': 1, 'nid': 1, 'yer': 1, 'var': 1, 'nor': 1, 'tur': 1, '##vor': 1, 'poste': 1, '##dur': 1, 'sage': 1, 'diverses': 1, 'generations': 1, 'precedents': 1, 'venus': 1, 'venant': 1, 'jouant': 1, 'evoluant': 1, 'amateurs': 1, 'invites': 1, 'jouent': 1, 'participant': 1, 'inscrits': 1, 'participent': 1, 'viennent': 1, 'vivent': 1, 'professionnels': 1, 'appeles': 1, 'vont': 1, 'lies': 1, 'entrant': 1, 'candidats': 1, 'deportes': 1, 'revenus': 1, 'resident': 1, 'propose': 1, 'constitue': 1, 'variant': 1, 'comprend': 1, 'initial': 1, 'general': 1, 'compris': 1, 'terrestre': 1, 'rural': 1, 'normal': 1, 'traditionnel': 1, 'atteint': 1, 'offre': 1, 'rail': 1, 'comportement': 1, '##un': 1, '##gun': 1, '##han': 1, '##une': 1, '##uni': 1, '##ul': 1, 'res': 1, 'amb': 1, 'trans': 1, 'ins': 1, 'pers': 1, 'rep': 1, 'der': 1, 'inc': 1, 'hy': 1, 'asp': 1, 'app': 1, 'inter': 1, 'pre': 1, 'co': 1, 'theo': 1, 'proces': 1, 'decouvrir': 1, 'trouver': 1, 'suivre': 1, 'rendre': 1, 'comprendre': 1, 'retrouver': 1, 'construire': 1, 'nature': 1, 'familles': 1, 'facon': 1, 'penser': 1, 'mettre': 1, 'visite': 1, 'navigation': 1, 'voyager': 1, '##duire': 1, 'langues': 1, 'animaux': 1, 'visiteurs': 1, 'mateix': 1, 'faveur': 1, 'transit': 1, 'acces': 1, 'transporte': 1, 'soutien': 1, 'prototype': 1, 'genie': 1, '&': 1, 'voire': 1, 'cites': 1, 'tr': 1, 'termini': 1, 'disques': 1, 'titres': 1, 'production': 1, 'formation': 1, '##pose': 1, 'presse': 1, 'position': 1, 'creation': 1, 'vehicule': 1, 'dispositif': 1, 'ge': 1, 'americains': 1, 'nationaux': 1, 'economiques': 1, 'internationaux': 1, 'militaires': 1, 'canadiens': 1, 'produits': 1, 'fiscaux': 1, 'americain': 1, 'sociaux': 1, 'agricoles': 1, 'automobiles': 1, 'locaux': 1, 'dollars': 1, 'relativement': 1, 'dits': 1, 'sales': 1, 'universitaires': 1, 'britanniques': 1, 'americaines': 1, 'publiques': 1, 'revenu': 1, 'remis': 1, 'envoye': 1, 'admis': 1, 'rendu': 1, 'laisse': 1, 'touche': 1, 'amene': 1, 'tombe': 1, 'roses': 1, 'brune': 1, 'vert': 1, 'gris': 1, 'bleue': 1, 'blanche': 1, 'noire': 1, 'roux': 1, 'male': 1, 'numero': 1, 'elle': 1, 'noel': 1, 'etang': 1, 'wagon': 1, 'velo': 1, 'compositeur': 1, 'tenor': 1, 'duo': 1, 'violon': 1, 'auteur': 1, 'tango': 1, 'classique': 1, 'valse': 1, 'orchestre': 1, 'trio': 1, 'monastere': 1, 'canton': 1, 'district': 1, 'red': 1, '##ed': 1, '##g': 1, '##uble': 1, '##nt': 1, '##gold': 1, '##b': 1, '##al': 1, '##cted': 1, 'active': 1, 'gratis': 1, 'collection': 1, 'auquel': 1, 'ont': 1, 'bristol': 1, 'manche': 1, 'aire': 1, 'lam': 1, 'cape': 1, 'tre': 1, 'lake': 1, 'lo': 1, 'vieille': 1, 'ham': 1, 'loire': 1, 'stoke': 1, 'lans': 1, 'nantes': 1, 'lune': 1, 'rouen': 1, 'londres': 1, 'lor': 1, 'bro': 1, 'sainte': 1, 'bourne': 1, '##et': 1, '##eur': 1, '##rier': 1, 'breton': 1, '»': 1, 'madagascar': 1, 'avions': 1, 'pilotes': 1, 'services': 1, 'airs': 1, 'passagers': 1, 'jets': 1, 'oiseaux': 1, 'seule': 1, 'connue': 1, 'commune': 1, 'freres': 1, 'soldats': 1, 'gens': 1, 'hommes': 1, 'rois': 1, 'travailleurs': 1, 'seigneurs': 1, 'amis': 1, 'vents': 1, 'montagne': 1, 'construction': 1, 'cadet': 1, 'shirt': 1, 'jeans': 1, 'fashion': 1, 'look': 1, 'ready': 1, 'girl': 1, 'kit': 1, 'jacket': 1, 'dress': 1, 'up': 1, 'exclusive': 1, 'pack': 1, 'box': 1, 'deluxe': 1, 'coupe': 1, 'clothes': 1, 'boy': 1, 'pop': 1, 'hoc': 1, 'serait': 1, 'devient': 1, 'concerne': 1, 'signifie': 1, 'apparait': 1, 'montre': 1, 'represente': 1, 'compare': 1, 'decrit': 1, 'explique': 1, 'correspond': 1, 'is': 1, 'existe': 1, 'illustre': 1, 'secondaires': 1, 'naturels': 1, 'particuliers': 1, 'intermediaires': 1, 'historiques': 1, '0': 1, '##ou': 1, '##po': 1, '##ha': 1, '##sky': 1, 'patri': 1, '##ho': 1, '##ka': 1, '##ol': 1, '##os': 1, '##li': 1, '##ra': 1, '##hi': 1, '##ri': 1, '##ky': 1, 'bac': 1, 'glacier': 1, 'aval': 1, 'motif': 1, '##rc': 1, 'nul': 1, 'collectif': 1, 'social': 1, 'expose': 1, 'specialiste': 1, 'sportif': 1, 'president': 1, 'hockey': 1, 'defenseur': 1, 'responsable': 1, 'altitude': 1, 'height': 1, 'grotte': 1, 'lange': 1, 'queue': 1, 'tete': 1, 'abandonne': 1, 'lance': 1, 'fixe': 1, 'concu': 1, 'modifie': 1, 'positif': 1, 'annonce': 1, 'realise': 1, 'menace': 1, 'soutenu': 1, 'souhaite': 1, 'refuse': 1, 'exige': 1, 'decline': 1, 'accepte': 1, 'dispute': 1, 'square': 1, 'kilometre': 1, 'handicap': 1, 'accidente': 1, 'miracle': 1, 'all': 1, 'other': 1, 'its': 1, 'their': 1, 'these': 1, 'his': 1, 'your': 1, 'two': 1, 'those': 1, 'various': 1, 'any': 1, 'several': 1, 'ten': 1, 'that': 1, 'our': 1, 'three': 1, 'most': 1, 'early': 1, 'every': 1, 'for': 1, 'dangerous': 1, 'ordinary': 1, 'four': 1, 'further': 1, 'over': 1, 'daily': 1, 'higher': 1, 'modern': 1, 'memorable': 1, 'devenu': 1, 'gagne': 1, 'classe': 1, '##me': 1, '10ᵉ': 1, 'huitieme': 1, '##zieme': 1, 'ventre': 1, 'tandis': 1, 'condition': 1, 'pendant': 1, 'nivel': 1, 'vague': 1, 'globe': 1, 'tas': 1, 'gps': 1, 'gras': 1, 'foot': 1, 'image': 1, 'vue': 1, 'maison': 1, 'etoile': 1, 'ouverture': 1, 'entree': 1, 'naissance': 1, 'celle': 1, 'cm': 1, 'centimetres': 1, 'diameter': 1, 'lorsque': 1, 'celsius': 1, 'lorsqu': 1}\n"
          ]
        }
      ],
      "source": [
        "print(sorted_word_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FupLjcv9GCy"
      },
      "outputs": [],
      "source": [
        "total_tokens = sum(sorted_word_frequency.values())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
